{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homeless-device",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randrange, choices\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-northern",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "https://www.kaggle.com/koki25ando/22000-scotch-whisky-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-charleston",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>review.point</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnnie Walker Blue Label, 40%</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>$</td>\n",
       "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Bowmore, 1964 vintage, 42 year old, 40.5%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>97</td>\n",
       "      <td>4500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bowmore 46 year old (distilled 1964), 42.9%</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>97</td>\n",
       "      <td>13500.00</td>\n",
       "      <td>$</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Compass Box The General, 53.4%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>325</td>\n",
       "      <td>$</td>\n",
       "      <td>With a name inspired by a 1926 Buster Keaton m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chivas Regal Ultis, 40%</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>96</td>\n",
       "      <td>160</td>\n",
       "      <td>$</td>\n",
       "      <td>Captivating, enticing, and wonderfully charmin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             name  \\\n",
       "0           1                   Johnnie Walker Blue Label, 40%   \n",
       "1           2  Black Bowmore, 1964 vintage, 42 year old, 40.5%   \n",
       "2           3      Bowmore 46 year old (distilled 1964), 42.9%   \n",
       "3           4                   Compass Box The General, 53.4%   \n",
       "4           5                          Chivas Regal Ultis, 40%   \n",
       "\n",
       "                     category  review.point     price currency  \\\n",
       "0       Blended Scotch Whisky            97       225        $   \n",
       "1          Single Malt Scotch            97   4500.00        $   \n",
       "2          Single Malt Scotch            97  13500.00        $   \n",
       "3  Blended Malt Scotch Whisky            96       325        $   \n",
       "4  Blended Malt Scotch Whisky            96       160        $   \n",
       "\n",
       "                                         description  \n",
       "0  Magnificently powerful and intense. Caramels, ...  \n",
       "1  What impresses me most is how this whisky evol...  \n",
       "2  There have been some legendary Bowmores from t...  \n",
       "3  With a name inspired by a 1926 Buster Keaton m...  \n",
       "4  Captivating, enticing, and wonderfully charmin...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"scotch_review.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "behavioral-poland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2247.000000\n",
       "mean      439.332443\n",
       "std       124.804400\n",
       "min        18.000000\n",
       "25%       380.000000\n",
       "50%       438.000000\n",
       "75%       481.000000\n",
       "max      1341.000000\n",
       "Name: description, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"description\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metallic-sight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2247.000000\n",
       "mean       86.700045\n",
       "std         4.054055\n",
       "min        63.000000\n",
       "25%        84.000000\n",
       "50%        87.000000\n",
       "75%        90.000000\n",
       "max        97.000000\n",
       "Name: review.point, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review.point\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stone-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[\"review.point\"])\n",
    "plt.savefig('reviewpoints.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "valued-tradition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Magnificently, powerful, and, intense, ., Car...\n",
       "1       [What, impresses, me, most, is, how, this, whi...\n",
       "2       [There, have, been, some, legendary, Bowmores,...\n",
       "3       [With, a, name, inspired, by, a, 1926, Buster,...\n",
       "4       [Captivating, ,, enticing, ,, and, wonderfully...\n",
       "                              ...                        \n",
       "2242    [Its, best, attributes, are, vanilla, ,, toast...\n",
       "2243    [Aged, in, a, sherry, cask, ,, which, adds, sw...\n",
       "2244    [Earthy, ,, fleshy, notes, with, brooding, gra...\n",
       "2245    [The, sherry, is, very, dominant, and, cloying...\n",
       "2246    [Fiery, peat, kiln, smoke, ,, tar, ,, and, rip...\n",
       "Name: description, Length: 2247, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data[\"description\"]  # just keep description\n",
    "training_data = training_data.str.findall(r\"[\\w]+|[''.,!?;]\")  # split words and punctuations (tokens)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intermediate-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "vocab = [token for review in training_data for token in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping from tokens to integer; and vice versa.\n",
    "dictionary = {}\n",
    "\n",
    "# list of tuples (tokens, freq).\n",
    "# Using Counter.most_common ensures that the mapping of the tokens is deterministic \n",
    "tokens_counts = Counter(vocab).most_common() \n",
    "\n",
    "# dictionary of token:int\n",
    "for i in range(len(tokens_counts)):\n",
    "    dictionary[tokens_counts[i][0]] = i\n",
    "\n",
    "# reverse dictionary of int:token\n",
    "reverse_dictionary = {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "important-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn list of tokens to a list of numbers\n",
    "def tokens_to_ids(tokens):\n",
    "    return list(map(dictionary.get, tokens))\n",
    "\n",
    "# turn list of numbers into a list of tokens\n",
    "def ids_to_tokens(ids):\n",
    "    return list(map(reverse_dictionary.get, ids))\n",
    "\n",
    "# turn list of tokens into string\n",
    "def tokens_to_string(tokens):\n",
    "    out = \"\"\n",
    "    \n",
    "    for token in tokens:\n",
    "        if any(p in token for p in punctuation):\n",
    "            out = out + token\n",
    "        elif not out or (out[-1] in [\".\", \";\"]):\n",
    "                out = out + \" \" + token.capitalize()\n",
    "        else:\n",
    "            out = out + \" \" + token.lower()\n",
    "    \n",
    "    # add ! or . randomly at the end\n",
    "    if out[-1] not in punctuation:\n",
    "        exclam = choices([0,1])[0]\n",
    "        if exclam:\n",
    "            out = out + \"!\"\n",
    "        else:\n",
    "            out = out + \".\"\n",
    "            \n",
    "    return out.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-spelling",
   "metadata": {},
   "source": [
    "### Create Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-talent",
   "metadata": {},
   "source": [
    "Create the training set by randomly picking sequences of tokens from our dataset of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "owned-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training samples\n",
    "n_train_samples = 50000 \n",
    "\n",
    "# length of sequence: this will be length of the training sequence plus one (prediction)\n",
    "sequence_length = 5\n",
    "\n",
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electoral-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sample(review, sequence_length):\n",
    "    sequence_start = randrange(len(review) - sequence_length)\n",
    "    sequence_end = sequence_start + sequence_length\n",
    "    sequence = review[sequence_start:sequence_end]\n",
    "    sequence = tokens_to_ids(sequence)\n",
    "    \n",
    "    input_sequence = sequence[:-1]\n",
    "    target = sequence[-1]\n",
    "    \n",
    "    return input_sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "median-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.loc[training_data.str.len() >= sequence_length]\n",
    "vocab_ids = []\n",
    "\n",
    "for i in range(n_train_samples):\n",
    "    review = training_data.sample(1).reset_index(drop = True)[0]\n",
    "    new_input, new_target = review_to_sample(review, sequence_length)\n",
    "    X_train.append(new_input)\n",
    "    y_train.append(new_target)\n",
    "    \n",
    "    # keep track of vocabulary in training set\n",
    "    vocab_ids = vocab_ids + np.unique(new_input).tolist() + [new_target]\n",
    "\n",
    "vocab_size = len(set(vocab_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "correct-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (n_train_samples, sequence_length - 1, 1))\n",
    "y_train = tf.keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-congo",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "LSTM with dropout to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "universal-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation = \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "transsexual-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 34s 86ms/step - loss: 6.2148\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 35s 90ms/step - loss: 5.6730\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 34s 86ms/step - loss: 5.4773\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 33s 85ms/step - loss: 5.3276\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 33s 85ms/step - loss: 5.1927\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 34s 88ms/step - loss: 5.0665\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 4.9611\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 4.8498 0s - loss: 4.\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 4.7454\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 4.6503\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 4.5620\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 4.4820 0s - l\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 4.4063\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 4.3370\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 37s 96ms/step - loss: 4.2699\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 4.2079\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 4.1495 0s - loss: 4.1\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 4.0979\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 4.0393\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 3.9967\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.9426\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.9044\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 3.8686\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.8211\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.7825\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.7490\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.7162\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.6779\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.6490\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.6106\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.5789\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.5532\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.5336\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 3.4965 0s - loss:\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.4731\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.4508\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.4231\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.4036\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.3815\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.3560\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.3365\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.3168\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.2893\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.2720\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.2585\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 3.2375\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 3.2202\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.2013\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 3.1837\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 3.1648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1710cf72430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "married-harris",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From E:\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: mainmodel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mainmodel2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-probe",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-parallel",
   "metadata": {},
   "source": [
    "It's possible to add more randomness using temperature, but I found that the output becomes too random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proof-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mainmodel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "precise-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given vector, choose next id stochastically.\n",
    "def vector_to_prediction(vector):\n",
    "    weights = vector.flatten().tolist()\n",
    "    pred = choices(population = list(range(len(weights))), weights = weights)\n",
    "    \n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifteen-westminster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2247.000000\n",
       "mean       87.597241\n",
       "std        24.921484\n",
       "min         2.000000\n",
       "25%        76.000000\n",
       "50%        87.000000\n",
       "75%        96.000000\n",
       "max       270.000000\n",
       "Name: description, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.str.len().describe() # data on the length of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "czech-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filtration layered rarer plant, rather, smoky, with cocoa apples freshly and caramel distilled. Vanilla, flowery forward, and a whiff. A shows expression. Honey expression, with soft white fragrant in a limited pipe when is company and matured. The palate initially robust! to the best palate, which ultimately emerge caol several. A smoke oily of honey initially fill to the end palate, which ultimately, toasted vanilla, blonde of flavor casks.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long text to generate\n",
    "# for simplicity just use uniform distribution on the IQR of training set review lengths.\n",
    "gen_length = choices(range(76,96))[0] \n",
    "\n",
    "# initialize random sequence of first words; \n",
    "# choose a number that is less than the existing vocabulary size if loading model\n",
    "# if model trained in current session, use vocab_size.\n",
    "curr_sequence = choices(range(5000), k = sequence_length - 1) \n",
    "gen_length = gen_length - len(curr_sequence)\n",
    "\n",
    "for i in range(gen_length):   \n",
    "    input_sequence = np.array(curr_sequence[-(sequence_length - 1):]).reshape(1, sequence_length - 1, 1)\n",
    "    output_vec = model.predict(input_sequence)\n",
    "    curr_sequence.append(vector_to_prediction(output_vec)) \n",
    "    \n",
    "# fake review\n",
    "tokens_to_string(ids_to_tokens(curr_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interstate-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This 1980 expression of The Dalmore Constellation has been solely matured in a Gonzales Byass Apostoles oloroso sherry butt. The resultant whisky is sweet on the nose, with dates, figs, milk chocolate-covered caramel, and finally a suggestion of eucalyptus. Briefly fruity on the palate, becoming bitter, with dark coffee notes. Long and spicy in the finish, with black pepper and licorice. Cask number 2140; 227 bottles. '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a real review\n",
    "data[\"description\"].sample(1).reset_index(drop=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
